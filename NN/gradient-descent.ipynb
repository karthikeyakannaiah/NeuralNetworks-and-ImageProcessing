{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-19 12:54:43.715399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-19 12:54:55.103565: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-19 12:54:55.103602: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-19 12:54:55.976013: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-19 12:55:13.018350: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-19 12:55:13.018882: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-19 12:55:13.018927: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>affordibility</th>\n",
       "      <th>bought_insurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  affordibility  bought_insurance\n",
       "0   22              1                 0\n",
       "1   25              0                 0\n",
       "2   47              1                 1\n",
       "3   52              0                 0\n",
       "4   46              1                 1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('assets/insurance_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[['age','affordibility']],df.bought_insurance, test_size=0.2, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>affordibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  affordibility\n",
       "0    22              1\n",
       "13   29              0\n",
       "6    55              0\n",
       "17   58              1\n",
       "24   50              1\n",
       "19   18              1\n",
       "25   54              1\n",
       "16   25              0\n",
       "20   21              1\n",
       "3    52              0\n",
       "7    60              0\n",
       "1    25              0\n",
       "5    56              1\n",
       "27   46              1\n",
       "8    62              1\n",
       "18   19              0\n",
       "12   27              0\n",
       "23   45              1\n",
       "22   40              1\n",
       "15   55              1\n",
       "26   23              1\n",
       "4    46              1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_train.copy()\n",
    "X_train_scaled['age'] = X_train_scaled['age'] / 100\n",
    "\n",
    "X_test_scaled = X_test.copy()\n",
    "X_test_scaled['age'] = X_test_scaled['age'] / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>affordibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  affordibility\n",
       "0   0.22              1\n",
       "13  0.29              0\n",
       "6   0.55              0\n",
       "17  0.58              1\n",
       "24  0.50              1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-19 12:55:40.397892: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-10-19 12:55:40.422168: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-10-19 12:55:40.422317: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (karthikeya): /proc/driver/nvidia/version does not exist\n",
      "2022-10-19 12:55:40.499958: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7113 - accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7110 - accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7106 - accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7102 - accuracy: 0.5000\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7098 - accuracy: 0.5000\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7094 - accuracy: 0.5000\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7091 - accuracy: 0.5000\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7087 - accuracy: 0.5000\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7083 - accuracy: 0.5000\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7079 - accuracy: 0.5000\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7076 - accuracy: 0.5000\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7072 - accuracy: 0.5000\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7068 - accuracy: 0.5000\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7065 - accuracy: 0.5000\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7061 - accuracy: 0.5000\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7057 - accuracy: 0.5000\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.7054 - accuracy: 0.5000\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7050 - accuracy: 0.5000\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7046 - accuracy: 0.5000\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.7043 - accuracy: 0.5000\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7039 - accuracy: 0.5000\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7035 - accuracy: 0.5000\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7032 - accuracy: 0.5000\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7028 - accuracy: 0.5000\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7025 - accuracy: 0.5000\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7021 - accuracy: 0.5000\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7017 - accuracy: 0.5000\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7014 - accuracy: 0.5000\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7010 - accuracy: 0.5000\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7007 - accuracy: 0.5000\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7003 - accuracy: 0.5000\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7000 - accuracy: 0.5000\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6996 - accuracy: 0.5000\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6993 - accuracy: 0.5000\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6989 - accuracy: 0.5000\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6986 - accuracy: 0.5000\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6982 - accuracy: 0.5000\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6979 - accuracy: 0.5000\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6975 - accuracy: 0.5000\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6972 - accuracy: 0.5000\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6969 - accuracy: 0.5000\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6965 - accuracy: 0.5000\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6962 - accuracy: 0.5000\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6958 - accuracy: 0.5000\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6955 - accuracy: 0.5000\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6952 - accuracy: 0.5000\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6948 - accuracy: 0.5000\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6945 - accuracy: 0.5000\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6942 - accuracy: 0.5000\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6938 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f73b87a8af0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(1, input_shape=(2,), activation='sigmoid', kernel_initializer='ones',bias_initializer='zeros')\n",
    "])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.fit(X_train_scaled,y_train,epochs=50)\n",
    "# needs to be done 5000 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 258ms/step - loss: 0.7108 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7107908129692078, 0.5]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 128ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.7938353 ],\n",
       "       [0.74505764],\n",
       "       [0.54927635],\n",
       "       [0.7626963 ],\n",
       "       [0.79693055],\n",
       "       [0.814774  ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef, intercept = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    import math\n",
    "    return 1/(1+math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_function(age, affordibility):\n",
    "    w1, w2 = coef\n",
    "    weighted_sum = w1*age + w2*affordibility + intercept\n",
    "    return sigmoid(weighted_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6273982274706037"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_function(0.6,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_numpy(X):\n",
    "    return 1/(1+np.exp(-X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99999386, 0.5       , 0.73105858])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_numpy(np.array([12,0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-15\n",
    "def log_loss(y_true, y_pred):\n",
    "    y_pred_new = [max(i,epsilon) for i in y_pred]\n",
    "    y_pred_new = [min(i,1-epsilon)  for i in y_pred_new]\n",
    "    y_pred_new = np.array(y_pred_new)\n",
    "    BCE = -np.mean(y_true*np.log(y_pred_new)+(1-y_true)*np.log(1-y_pred_new))\n",
    "    return BCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(age,affordibility, y_true, epochs, loss_threshold):\n",
    "    # w1, w2, bias\n",
    "    w1 = w2 = 1\n",
    "    bias = 0\n",
    "    rate = 0.5\n",
    "    n = len(age)\n",
    "    for i in range(epochs):\n",
    "        weighted_sum = w1*age + w2*affordibility + bias\n",
    "        y_pred = sigmoid_numpy(weighted_sum)\n",
    "        loss = log_loss(y_true, y_pred)\n",
    "\n",
    "        d_w1 = (1/n)*np.dot(np.transpose(age),(y_pred-y_true))\n",
    "        d_w2 = (1/n)*np.dot(np.transpose(affordibility),(y_pred-y_true))\n",
    "        d_bias = np.mean(y_pred-y_true)\n",
    "\n",
    "        w1 = w1 - rate * d_w1\n",
    "        w2 = w2 - rate * d_w2\n",
    "        bias = bias - rate * d_bias\n",
    "\n",
    "        print(f'epoch:{i}, w1:{w1}, w2:{w2}, bias:{bias}, loss:{loss}')\n",
    "\n",
    "        if loss <= loss_threshold:\n",
    "            break\n",
    "\n",
    "    return w1, w2, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, w1:0.974907633470177, w2:0.948348125394529, bias:-0.11341867736368583, loss:0.7113403233723417\n",
      "epoch:1, w1:0.9556229728273669, w2:0.9058873696677865, bias:-0.2122349122718517, loss:0.681264778737757\n",
      "epoch:2, w1:0.9416488476693794, w2:0.8719790823960313, bias:-0.2977578997796538, loss:0.6591474252715025\n",
      "epoch:3, w1:0.9323916996249162, w2:0.8457541517722915, bias:-0.3715094724003511, loss:0.6431523291301917\n",
      "epoch:4, w1:0.9272267472726993, w2:0.8262362885332687, bias:-0.43506643026891584, loss:0.6316873063379158\n",
      "epoch:5, w1:0.9255469396815343, w2:0.8124402814952774, bias:-0.48994490058938817, loss:0.623471707997592\n",
      "epoch:6, w1:0.9267936114129968, w2:0.8034375029757677, bias:-0.5375299543522853, loss:0.6175321183044205\n",
      "epoch:7, w1:0.93047170420295, w2:0.7983920007454487, bias:-0.5790424270894963, loss:0.6131591858705934\n",
      "epoch:8, w1:0.9361540784567942, w2:0.7965748796787705, bias:-0.6155315088627655, loss:0.6098518179750948\n",
      "epoch:9, w1:0.9434791243557357, w2:0.7973647616854131, bias:-0.6478828179413606, loss:0.6072639970231438\n",
      "epoch:10, w1:0.9521448361628082, w2:0.8002404280558159, bias:-0.6768343869109611, loss:0.6051606942838051\n",
      "epoch:11, w1:0.9619014360798376, w2:0.8047697991276092, bias:-0.7029956527236098, loss:0.6033841405177724\n",
      "epoch:12, w1:0.9725437902239876, w2:0.8105978078160995, bias:-0.7268665798879941, loss:0.6018292976282692\n",
      "epoch:13, w1:0.9839042828641819, w2:0.8174345999952901, bias:-0.7488554155033402, loss:0.6004266142491015\n",
      "epoch:14, w1:0.9958464546516588, w2:0.8250447751055391, bias:-0.769294418817745, loss:0.5991301804031037\n",
      "epoch:15, w1:1.0082595007242081, w2:0.8332379503132499, bias:-0.7884533918133878, loss:0.5979097221992564\n",
      "epoch:16, w1:1.0210536111133566, w2:0.8418606908070436, bias:-0.8065510935633605, loss:0.5967452540340851\n",
      "epoch:17, w1:1.034156080666481, w2:0.8507897246509063, bias:-0.8237647415878959, loss:0.5956235357679642\n",
      "epoch:18, w1:1.0475080939682688, w2:0.8599263049589658, bias:-0.8402378469114854, loss:0.5945357398126384\n",
      "epoch:19, w1:1.0610620872868053, w2:0.8691915649552581, bias:-0.8560866317233403, loss:0.5934759216594547\n",
      "epoch:20, w1:1.0747795953648005, w2:0.8785227146485403, bias:-0.8714052604012273, loss:0.5924400203169505\n",
      "epoch:21, w1:1.0886295007650375, w2:0.8878699408379153, bias:-0.8862700880092956, loss:0.5914252065214394\n",
      "epoch:22, w1:1.1025866146156011, w2:0.8971938890119441, bias:-0.9007431016492755, loss:0.5904294583596238\n",
      "epoch:23, w1:1.1166305284975315, w2:0.9064636231844676, bias:-0.9148747025148294, loss:0.5894512852039241\n",
      "epoch:24, w1:1.130744687166233, w2:0.9156549761872753, bias:-0.9287059516737735, loss:0.5884895481881011\n",
      "epoch:25, w1:1.1449156405234902, w2:0.9247492176815199, bias:-0.9422703810055986, loss:0.5875433434377384\n",
      "epoch:26, w1:1.1591324407175467, w2:0.9337319799254573, bias:-0.9555954523596437, loss:0.5866119260562087\n",
      "epoch:27, w1:1.1733861565198167, w2:0.9425923921787205, bias:-0.9687037326284236, loss:0.5856946605640079\n",
      "epoch:28, w1:1.1876694823356402, w2:0.9513223836938425, bias:-0.9816138397030203, loss:0.5847909885040025\n",
      "epoch:29, w1:1.2019764234961199, w2:0.9599161227563919, bias:-0.994341203820797, loss:0.5839004071862915\n",
      "epoch:30, w1:1.2163020429886013, w2:0.9683695654077998, bias:-1.006898680274023, loss:0.5830224556644095\n",
      "epoch:31, w1:1.2306422576428844, w2:0.9766800925300213, bias:-1.0192970425003876, loss:0.5821567054089575\n",
      "epoch:32, w1:1.244993674111329, w2:0.9848462180774323, bias:-1.0315453789434794, loss:0.5813027540359855\n",
      "epoch:33, w1:1.2593534568600255, w2:0.9928673545729692, bias:-1.0436514125153917, loss:0.5804602210251408\n",
      "epoch:34, w1:1.2737192219062514, w2:1.0007436246821175, bias:-1.0556217578155669, loss:0.5796287447370064\n",
      "epoch:35, w1:1.2880889512619975, w2:1.0084757098569885, bias:-1.067462128294764, loss:0.57880798028165\n",
      "epoch:36, w1:1.3024609240300042, w2:1.0160647288004139, bias:-1.079177503164993, loss:0.5779975979476322\n",
      "epoch:37, w1:1.3168336608930384, w2:1.0235121399165894, bias:-1.0907722619345364, loss:0.5771972820026156\n",
      "epoch:38, w1:1.3312058793761508, w2:1.0308196630555955, bias:-1.1022502929016078, loss:0.5764067297427645\n",
      "epoch:39, w1:1.3455764577755067, w2:1.03798921677727, bias:-1.1136150806976406, loss:0.5756256507109632\n",
      "epoch:40, w1:1.3599444060604624, w2:1.0450228680985851, bias:-1.124869776972519, loss:0.5748537660316542\n",
      "epoch:41, w1:1.3743088423875545, w2:1.0519227922827652, bias:-1.1360172575115421, loss:0.5740908078281305\n",
      "epoch:42, w1:1.3886689741318716, w2:1.0586912407061275, bias:-1.1470601684290498, loss:0.5733365186998219\n",
      "epoch:43, w1:1.4030240825556768, w2:1.065330515222758, bias:-1.1580009635655026, loss:0.5725906512447178\n",
      "epoch:44, w1:1.4173735104064382, w2:1.0718429477560005, bias:-1.1688419347984433, loss:0.5718529676170188\n",
      "epoch:45, w1:1.4317166518748927, w2:1.0782308840940895, bias:-1.1795852366431911, loss:0.5711232391133308\n",
      "epoch:46, w1:1.4460529444550507, w2:1.0844966710669584, bias:-1.1902329062502135, loss:0.5704012457828124\n",
      "epoch:47, w1:1.4603818623375084, w2:1.0906426464418717, bias:-1.2007868796899672, loss:0.5696867760580651\n",
      "epoch:48, w1:1.474702911039356, w2:1.0966711310047097, bias:-1.2112490052422353, loss:0.5689796264044564\n",
      "epoch:49, w1:1.4890156230318012, w2:1.1025844223976542, bias:-1.2216210542672539, loss:0.5682796009861607\n",
      "epoch:50, w1:1.503319554173139, w2:1.108384790367645, bias:-1.2319047301235464, loss:0.5675865113475955\n",
      "epoch:51, w1:1.5176142807921111, w2:1.1140744731472638, bias:-1.2421016755069894, loss:0.5669001761092021\n",
      "epoch:52, w1:1.5318993972968091, w2:1.1196556747438646, bias:-1.2522134785128962, loss:0.566220420676692\n",
      "epoch:53, w1:1.546174514208496, w2:1.1251305629563741, bias:-1.2622416776643735, loss:0.5655470769630154\n",
      "epoch:54, w1:1.5604392565392238, w2:1.1305012679742994, bias:-1.2721877661030871, loss:0.5648799831223866\n",
      "epoch:55, w1:1.5746932624478314, w2:1.1357698814417572, bias:-1.2820531951006382, loss:0.5642189832957764\n",
      "epoch:56, w1:1.5889361821215457, w2:1.1409384558921223, bias:-1.2918393770181935, loss:0.5635639273673236\n",
      "epoch:57, w1:1.6031676768405996, w2:1.1460090044772484, bias:-1.3015476878174077, loss:0.562914670731162\n",
      "epoch:58, w1:1.6173874181914885, w2:1.150983500930006, bias:-1.3111794692058374, loss:0.5622710740681858\n",
      "epoch:59, w1:1.6315950874010996, w2:1.155863879710811, bias:-1.320736030484068, loss:0.5616330031323111\n",
      "epoch:60, w1:1.6457903747692835, w2:1.1606520362984267, bias:-1.3302186501488862, loss:0.5610003285458062\n",
      "epoch:61, w1:1.6599729791817353, w2:1.1653498275930778, bias:-1.3396285772964385, loss:0.5603729256032908\n",
      "epoch:62, w1:1.6741426076885264, w2:1.1699590724061661, bias:-1.348967032860937, loss:0.5597506740840237\n",
      "epoch:63, w1:1.6882989751364197, w2:1.1744815520159209, bias:-1.3582352107177078, loss:0.5591334580721091\n",
      "epoch:64, w1:1.7024418038453646, w2:1.1789190107723873, bias:-1.3674342786739169, loss:0.5585211657842806\n",
      "epoch:65, w1:1.7165708233213919, w2:1.1832731567384374, bias:-1.3765653793659074, loss:0.5579136894049259\n",
      "epoch:66, w1:1.7306857699995972, w2:1.1875456623561378, bias:-1.385629631078514, loss:0.5573109249280388\n",
      "epoch:67, w1:1.744786387012096, w2:1.1917381651299463, bias:-1.3946281284988502, loss:0.556712772005794\n",
      "epoch:68, w1:1.7588724239767908, w2:1.1958522683199346, bias:-1.4035619434147377, loss:0.5561191338034575\n",
      "epoch:69, w1:1.7729436368035707, w2:1.199889541639625, bias:-1.412432125366066, loss:0.5555299168603557\n",
      "epoch:70, w1:1.786999787515191, w2:1.2038515219541523, bias:-1.4212397022558536, loss:0.55494503095664\n",
      "epoch:71, w1:1.8010406440805895, w2:1.2077397139753707, bias:-1.4299856809265468, loss:0.5543643889855958\n",
      "epoch:72, w1:1.815065980258806, w2:1.21155559095125, bias:-1.4386710477060998, loss:0.5537879068312537\n",
      "epoch:73, w1:1.8290755754520085, w2:1.2153005953475013, bias:-1.4472967689275704, loss:0.5532155032510755\n",
      "epoch:74, w1:1.8430692145663952, w2:1.2189761395198406, bias:-1.4558637914253105, loss:0.5526470997634942\n",
      "epoch:75, w1:1.857046687879965, w2:1.2225836063756854, bias:-1.4643730430103006, loss:0.5520826205400979\n",
      "epoch:76, w1:1.8710077909163219, w2:1.2261243500243837, bias:-1.472825432926746, loss:0.5515219923022593\n",
      "epoch:77, w1:1.8849523243238275, w2:1.2295996964153224, bias:-1.4812218522917016, loss:0.5509651442220168\n",
      "epoch:78, w1:1.898880093759531, w2:1.2330109439634602, bias:-1.4895631745192046, loss:0.5504120078270269\n",
      "epoch:79, w1:1.9127909097773987, w2:1.2363593641619885, bias:-1.4978502557301687, loss:0.5498625169094129\n",
      "epoch:80, w1:1.9266845877204517, w2:1.2396462021819508, bias:-1.5060839351490927, loss:0.5493166074383391\n",
      "epoch:81, w1:1.9405609476164691, w2:1.2428726774587495, bias:-1.5142650354884937, loss:0.5487742174761587\n",
      "epoch:82, w1:1.9544198140769822, w2:1.2460399842655545, bias:-1.5223943633218389, loss:0.5482352870979753\n",
      "epoch:83, w1:1.968261016199314, w2:1.2491492922736824, bias:-1.5304727094456483, loss:0.5476997583144769\n",
      "epoch:84, w1:1.9820843874714607, w2:1.252201747100074, bias:-1.538500849231359, loss:0.5471675749979029\n",
      "epoch:85, w1:1.995889765679638, w2:1.2551984708420285, bias:-1.5464795429674643, loss:0.5466386828110088\n",
      "epoch:86, w1:2.0096769928183367, w2:1.2581405625993878, bias:-1.554409536192387, loss:0.5461130291389041\n",
      "epoch:87, w1:2.023445915002755, w2:1.2610290989843815, bias:-1.5622915600184968, loss:0.545590563023641\n",
      "epoch:88, w1:2.037196382383489, w2:1.2638651346193672, bias:-1.5701263314476384, loss:0.5450712351014357\n",
      "epoch:89, w1:2.0509282490633733, w2:1.2666497026227028, bias:-1.577914553678509, loss:0.5445549975424178\n",
      "epoch:90, w1:2.0646413730163813, w2:1.2693838150830055, bias:-1.585656916406187, loss:0.5440418039927909\n",
      "epoch:91, w1:2.0783356160084976, w2:1.2720684635220503, bias:-1.5933540961140944, loss:0.5435316095193146\n",
      "epoch:92, w1:2.092010843520487, w2:1.2747046193465692, bias:-1.6010067563586592, loss:0.5430243705560023\n",
      "epoch:93, w1:2.1056669246724873, w2:1.2772932342892063, bias:-1.6086155480469115, loss:0.5425200448529465\n",
      "epoch:94, w1:2.1193037321503643, w2:1.2798352408388918, bias:-1.6161811097072503, loss:0.5420185914271816\n",
      "epoch:95, w1:2.1329211421337653, w2:1.282331552660889, bias:-1.62370406775359, loss:0.5415199705154982\n",
      "epoch:96, w1:2.1465190342258187, w2:1.2847830650067702, bias:-1.6311850367430925, loss:0.5410241435291299\n",
      "epoch:97, w1:2.1600972913844236, w2:1.2871906551145709, bias:-1.638624619627673, loss:0.5405310730102341\n",
      "epoch:98, w1:2.173655799855084, w2:1.2895551825993699, bias:-1.6460234079994696, loss:0.5400407225900913\n",
      "epoch:99, w1:2.1871944491052364, w2:1.2918774898345378, bias:-1.6533819823304428, loss:0.5395530569489538\n",
      "epoch:100, w1:2.200713131760032, w2:1.2941584023238903, bias:-1.6607009122062801, loss:0.5390680417774752\n",
      "epoch:101, w1:2.2142117435395288, w2:1.2963987290649803, bias:-1.667980756554761, loss:0.5385856437396539\n",
      "epoch:102, w1:2.227690183197251, w2:1.298599262903754, bias:-1.675222063868738, loss:0.5381058304372313\n",
      "epoch:103, w1:2.241148352460086, w2:1.300760780880796, bias:-1.6824253724238831, loss:0.5376285703754836\n",
      "epoch:104, w1:2.2545861559694704, w2:1.302884044569378, bias:-1.68959121049134, loss:0.5371538329303491\n",
      "epoch:105, w1:2.268003501223843, w2:1.3049698004055226, bias:-1.696720096545423, loss:0.5366815883168389\n",
      "epoch:106, w1:2.281400298522321, w2:1.30701878001029, bias:-1.7038125394664934, loss:0.5362118075586769\n",
      "epoch:107, w1:2.294776460909571, w2:1.3090317005044871, bias:-1.7108690387391425, loss:0.5357444624591193\n",
      "epoch:108, w1:2.308131904121845, w2:1.3110092648159952, bias:-1.717890084645807, loss:0.5352795255729065\n",
      "epoch:109, w1:2.3214665465341486, w2:1.3129521619799067, bias:-1.7248761584559342, loss:0.5348169701793002\n",
      "epoch:110, w1:2.334780309108516, w2:1.3148610674316565, bias:-1.7318277326108187, loss:0.5343567702561651\n",
      "epoch:111, w1:2.3480731153433556, w2:1.3167366432933292, bias:-1.7387452709042173, loss:0.5338989004550466\n",
      "epoch:112, w1:2.361344891223853, w2:1.318579538653317, bias:-1.7456292286588566, loss:0.5334433360772121\n",
      "epoch:113, w1:2.3745955651733888, w2:1.3203903898394993, bias:-1.752480052898938, loss:0.5329900530506113\n",
      "epoch:114, w1:2.387825068005961, w2:1.3221698206861112, bias:-1.759298182518741, loss:0.532539027907722\n",
      "epoch:115, w1:2.4010333328795768, w2:1.3239184427944621, bias:-1.7660840484474298, loss:0.5320902377642434\n",
      "epoch:116, w1:2.4142202952505927, w2:1.3256368557876617, bias:-1.772838073810153, loss:0.5316436602986057\n",
      "epoch:117, w1:2.427385892828985, w2:1.3273256475595065, bias:-1.7795606740855376, loss:0.5311992737322607\n",
      "epoch:118, w1:2.440530065534521, w2:1.328985394517677, bias:-1.7862522572596642, loss:0.5307570568107249\n",
      "epoch:119, w1:2.4536527554538115, w2:1.3306166618213877, bias:-1.7929132239766132, loss:0.5303169887853427\n",
      "epoch:120, w1:2.46675390679823, w2:1.332220003613633, bias:-1.7995439676856702, loss:0.5298790493957434\n",
      "epoch:121, w1:2.479833465862666, w2:1.3337959632481655, bias:-1.8061448747852695, loss:0.5294432188529623\n",
      "epoch:122, w1:2.4928913809851023, w2:1.3353450735113397, bias:-1.8127163247637639, loss:0.5290094778232023\n",
      "epoch:123, w1:2.505927602506996, w2:1.336867856838949, bias:-1.8192586903370926, loss:0.5285778074122077\n",
      "epoch:124, w1:2.518942082734439, w2:1.3383648255281848, bias:-1.82577233758343, loss:0.5281481891502279\n",
      "epoch:125, w1:2.5319347759000843, w2:1.3398364819448387, bias:-1.832257626074885, loss:0.5277206049775486\n",
      "epoch:126, w1:2.5449056381258233, w2:1.341283318725866, bias:-1.8387149090063277, loss:0.5272950372305655\n",
      "epoch:127, w1:2.557854627386187, w2:1.3427058189774277, bias:-1.8451445333214114, loss:0.5268714686283816\n",
      "epoch:128, w1:2.570781703472466, w2:1.3441044564685243, bias:-1.851546839835858, loss:0.5264498822599072\n",
      "epoch:129, w1:2.583686827957526, w2:1.345479695820328, bias:-1.857922163358077, loss:0.5260302615714416\n",
      "epoch:130, w1:2.596569964161304, w2:1.346831992691322, bias:-1.8642708328071762, loss:0.5256125903547197\n",
      "epoch:131, w1:2.6094310771169726, w2:1.3481617939583521, bias:-1.8705931713284367, loss:0.5251968527354035\n",
      "epoch:132, w1:2.6222701335377554, w2:1.3494695378936876, bias:-1.8768894964063034, loss:0.524783033162003\n",
      "epoch:133, w1:2.635087101784378, w2:1.3507556543381913, bias:-1.8831601199749577, loss:0.5243711163952075\n",
      "epoch:134, w1:2.647881951833145, w2:1.3520205648706964, bias:-1.8894053485265268, loss:0.5239610874976152\n",
      "epoch:135, w1:2.660654655244622, w2:1.353264682973678, bias:-1.8956254832169885, loss:0.5235529318238407\n",
      "epoch:136, w1:2.6734051851329177, w2:1.3544884141953148, bias:-1.901820819969824, loss:0.5231466350109902\n",
      "epoch:137, w1:2.686133516135547, w2:1.3556921563080242, bias:-1.9079916495774736, loss:0.5227421829694884\n",
      "epoch:138, w1:2.6988396243838655, w2:1.3568762994635601, bias:-1.9141382578006458, loss:0.5223395618742417\n",
      "epoch:139, w1:2.7115234874740595, w2:1.3580412263447545, bias:-1.920260925465534, loss:0.5219387581561296\n",
      "epoch:140, w1:2.724185084438686, w2:1.3591873123139828, bias:-1.9263599285589843, loss:0.521539758493806\n",
      "epoch:141, w1:2.736824395718745, w2:1.3603149255584348, bias:-1.9324355383216678, loss:0.5211425498058037\n",
      "epoch:142, w1:2.7494414031362733, w2:1.3614244272322646, bias:-1.9384880213393003, loss:0.5207471192429267\n",
      "epoch:143, w1:2.7620360898674554, w2:1.3625161715956964, bias:-1.9445176396319575, loss:0.5203534541809204\n",
      "epoch:144, w1:2.7746084404162294, w2:1.363590506151157, bias:-1.9505246507415273, loss:0.5199615422134104\n",
      "epoch:145, w1:2.787158440588389, w2:1.364647771776508, bias:-1.9565093078173448, loss:0.5195713711450981\n",
      "epoch:146, w1:2.7996860774661636, w2:1.3656883028554423, bias:-1.9624718597000501, loss:0.5191829289852049\n",
      "epoch:147, w1:2.812191339383268, w2:1.3667124274051172, bias:-1.9684125510037105, loss:0.5187962039411522\n",
      "epoch:148, w1:2.824674215900416, w2:1.3677204672010856, bias:-1.974331622196247, loss:0.5184111844124737\n",
      "epoch:149, w1:2.8371346977812824, w2:1.3687127378995887, bias:-1.9802293096782038, loss:0.5180278589849453\n",
      "epoch:150, w1:2.8495727769689085, w2:1.3696895491572745, bias:-1.986105845859897, loss:0.5176462164249294\n",
      "epoch:151, w1:2.861988446562542, w2:1.3706512047484, bias:-1.9919614592369834, loss:0.5172662456739209\n",
      "epoch:152, w1:2.8743817007948973, w2:1.3715980026795769, bias:-1.9977963744644796, loss:0.5168879358432925\n",
      "epoch:153, w1:2.886752535009837, w2:1.3725302353021163, bias:-2.003610812429271, loss:0.5165112762092271\n",
      "epoch:154, w1:2.899100945640455, w2:1.373448189422031, bias:-2.009404990321143, loss:0.5161362562078318\n",
      "epoch:155, w1:2.9114269301875644, w2:1.3743521464077455, bias:-2.015179121702366, loss:0.515762865430428\n",
      "epoch:156, w1:2.9237304871985708, w2:1.3752423822955708, bias:-2.0209334165758692, loss:0.5153910936190104\n",
      "epoch:157, w1:2.9360116162467342, w2:1.376119167892991, bias:-2.0266680814520357, loss:0.515020930661866\n",
      "epoch:158, w1:2.9482703179108047, w2:1.3769827688798149, bias:-2.032383319414142, loss:0.5146523665893518\n",
      "epoch:159, w1:2.960506593755025, w2:1.3778334459072408, bias:-2.038079330182483, loss:0.514285391569821\n",
      "epoch:160, w1:2.9727204463094963, w2:1.3786714546948804, bias:-2.0437563101772027, loss:0.5139199959056945\n",
      "epoch:161, w1:2.984911879050898, w2:1.3794970461257903, bias:-2.0494144525798648, loss:0.5135561700296716\n",
      "epoch:162, w1:2.9970808963835545, w2:1.3803104663395542, bias:-2.0550539473937857, loss:0.5131939045010747\n",
      "epoch:163, w1:3.0092275036208402, w2:1.3811119568234618, bias:-2.0606749815031633, loss:0.5128331900023233\n",
      "epoch:164, w1:3.0213517069669225, w2:1.3819017545018246, bias:-2.0662777387310216, loss:0.5124740173355311\n",
      "epoch:165, w1:3.0334535134988276, w2:1.382680091823474, bias:-2.0718623998960024, loss:0.5121163774192251\n",
      "epoch:166, w1:3.045532931148832, w2:1.3834471968474789, bias:-2.0774291428680245, loss:0.5117602612851783\n",
      "epoch:167, w1:3.0575899686871653, w2:1.384203293327124, bias:-2.08297814262284, loss:0.511405660075352\n",
      "epoch:168, w1:3.069624635705023, w2:1.384948600792189, bias:-2.0885095712955057, loss:0.5110525650389491\n",
      "epoch:169, w1:3.081636942597884, w2:1.385683334629563, bias:-2.094023598232799, loss:0.5107009675295656\n",
      "epoch:170, w1:3.093626900549122, w2:1.386407706162234, bias:-2.0995203900445953, loss:0.5103508590024443\n",
      "epoch:171, w1:3.105594521513913, w2:1.387121922726688, bias:-2.1050001106542355, loss:0.5100022310118232\n",
      "epoch:172, w1:3.117539818203424, w2:1.387826187748753, bias:-2.110462921347898, loss:0.5096550752083747\n",
      "epoch:173, w1:3.1294628040692873, w2:1.3885207008179221, bias:-2.1159089808230034, loss:0.5093093833367357\n",
      "epoch:174, w1:3.141363493288346, w2:1.3892056577601883, bias:-2.121338445235668, loss:0.5089651472331199\n",
      "epoch:175, w1:3.1532419007476733, w2:1.389881250709425, bias:-2.1267514682472277, loss:0.5086223588230153\n",
      "epoch:176, w1:3.165098042029856, w2:1.390547668177342, bias:-2.132148201069852, loss:0.5082810101189588\n",
      "epoch:177, w1:3.176931933398537, w2:1.3912050951220503, bias:-2.1375287925112674, loss:0.5079410932183875\n",
      "epoch:178, w1:3.188743591784215, w2:1.3918537130152622, bias:-2.1428933890186115, loss:0.5076026003015645\n",
      "epoch:179, w1:3.200533034770296, w2:1.3924936999081612, bias:-2.1482421347214276, loss:0.5072655236295737\n",
      "epoch:180, w1:3.212300280579388, w2:1.3931252304959654, bias:-2.1535751714738307, loss:0.5069298555423847\n",
      "epoch:181, w1:3.2240453480598403, w2:1.3937484761812156, bias:-2.158892638895851, loss:0.5065955884569808\n",
      "epoch:182, w1:3.235768256672519, w2:1.3943636051358148, bias:-2.1641946744139777, loss:0.5062627148655543\n",
      "epoch:183, w1:3.2474690264778157, w2:1.394970782361845, bias:-2.1694814133009186, loss:0.505931227333758\n",
      "epoch:184, w1:3.2591476781228836, w2:1.3955701697511878, bias:-2.1747529887145927, loss:0.5056011184990193\n",
      "epoch:185, w1:3.270804232829102, w2:1.3961619261439753, bias:-2.1800095317363692, loss:0.505272381068909\n",
      "epoch:186, w1:3.2824387123797556, w2:1.3967462073858943, bias:-2.185251171408572, loss:0.5049450078195657\n",
      "epoch:187, w1:3.294051139107937, w2:1.3973231663843697, bias:-2.1904780347712607, loss:0.5046189915941715\n",
      "epoch:188, w1:3.3056415358846545, w2:1.3978929531636493, bias:-2.1956902468983084, loss:0.5042943253014793\n",
      "epoch:189, w1:3.317209926107157, w2:1.3984557149188142, bias:-2.2008879309327845, loss:0.5039710019143897\n",
      "epoch:190, w1:3.3287563336874557, w2:1.3990115960687382, bias:-2.2060712081216627, loss:0.5036490144685731\n",
      "epoch:191, w1:3.340280783041054, w2:1.3995607383080155, bias:-2.211240197849864, loss:0.5033283560611389\n",
      "epoch:192, w1:3.351783299075871, w2:1.400103280657881, bias:-2.21639501767365, loss:0.5030090198493474\n",
      "epoch:193, w1:3.3632639071813593, w2:1.4006393595161428, bias:-2.221535783353378, loss:0.502690999049364\n",
      "epoch:194, w1:3.3747226332178184, w2:1.401169108706148, bias:-2.2266626088856363, loss:0.502374286935055\n",
      "epoch:195, w1:3.3861595035058896, w2:1.4016926595248012, bias:-2.231775606534763, loss:0.5020588768368214\n",
      "epoch:196, w1:3.3975745448162384, w2:1.4022101407896574, bias:-2.236874886863771, loss:0.5017447621404708\n",
      "epoch:197, w1:3.408967784359416, w2:1.4027216788851056, bias:-2.2419605587646827, loss:0.5014319362861261\n",
      "epoch:198, w1:3.4203392497759015, w2:1.4032273978076624, bias:-2.247032729488292, loss:0.5011203927671694\n",
      "epoch:199, w1:3.4316889691263146, w2:1.4037274192103975, bias:-2.252091504673362, loss:0.5008101251292182\n",
      "epoch:200, w1:3.443016970881803, w2:1.4042218624465033, bias:-2.2571369883752723, loss:0.5005011269691375\n",
      "epoch:201, w1:3.4543232839145968, w2:1.4047108446120309, bias:-2.2621692830941247, loss:0.5001933919340792\n",
      "epoch:202, w1:3.4656079374887283, w2:1.4051944805878065, bias:-2.2671884898023182, loss:0.4998869137205552\n",
      "epoch:203, w1:3.4768709612509157, w2:1.4056728830805474, bias:-2.2721947079716065, loss:0.499581686073539\n",
      "epoch:204, w1:3.4881123852216054, w2:1.4061461626631908, bias:-2.2771880355996448, loss:0.4992777027855931\n",
      "epoch:205, w1:3.4993322397861726, w2:1.406614427814455, bias:-2.282168569236039, loss:0.4989749576960279\n",
      "epoch:206, w1:3.510530555686274, w2:1.407077784957646, bias:-2.287136404007907, loss:0.4986734446900829\n",
      "epoch:207, w1:3.5217073640113545, w2:1.407536338498725, bias:-2.2920916336449575, loss:0.49837315769813556\n",
      "epoch:208, w1:3.5328626961903016, w2:1.4079901908636536, bias:-2.2970343505041027, loss:0.49807409069493364\n",
      "epoch:209, w1:3.5439965839832466, w2:1.4084394425350295, bias:-2.30196464559361, loss:0.49777623769885115\n",
      "epoch:210, w1:3.5551090594735104, w2:1.4088841920880264, bias:-2.3068826085968004, loss:0.49747959277116743\n",
      "epoch:211, w1:3.5662001550596885, w2:1.4093245362256548, bias:-2.3117883278953073, loss:0.4971841500153676\n",
      "epoch:212, w1:3.577269903447877, w2:1.4097605698133546, bias:-2.3166818905919, loss:0.4968899035764641\n",
      "epoch:213, w1:3.5883183376440364, w2:1.4101923859129344, bias:-2.321563382532884, loss:0.49659684764033973\n",
      "epoch:214, w1:3.5993454909464844, w2:1.4106200758158696, bias:-2.32643288833008, loss:0.49630497643310856\n",
      "epoch:215, w1:3.610351396938527, w2:1.4110437290759732, bias:-2.331290491382403, loss:0.49601428422049737\n",
      "epoch:216, w1:3.6213360894812157, w2:1.4114634335414504, bias:-2.3361362738970306, loss:0.4957247653072439\n",
      "epoch:217, w1:3.6322996027062318, w2:1.4118792753863514, bias:-2.3409703169101865, loss:0.49543641403651506\n",
      "epoch:218, w1:3.6432419710088983, w2:1.4122913391414305, bias:-2.345792700307536, loss:0.49514922478933926\n",
      "epoch:219, w1:3.6541632290413135, w2:1.4126997077244283, bias:-2.350603502844203, loss:0.4948631919840572\n",
      "epoch:220, w1:3.6650634117056042, w2:1.4131044624697842, bias:-2.3554028021644196, loss:0.49457831007578845\n",
      "epoch:221, w1:3.6759425541473023, w2:1.4135056831577921, bias:-2.360190674820809, loss:0.4942945735559119\n",
      "epoch:222, w1:3.6868006917488327, w2:1.4139034480432113, bias:-2.3649671962933168, loss:0.49401197695156235\n",
      "epoch:223, w1:3.6976378601231215, w2:1.4142978338833405, bias:-2.3697324410077902, loss:0.4937305148251413\n",
      "epoch:224, w1:3.7084540951073124, w2:1.4146889159655687, bias:-2.3744864823542158, loss:0.49345018177384004\n",
      "epoch:225, w1:3.719249432756598, w2:1.4150767681344103, bias:-2.379229392704622, loss:0.49317097242917785\n",
      "epoch:226, w1:3.7300239093381586, w2:1.4154614628180373, bias:-2.383961243430653, loss:0.4928928814565522\n",
      "epoch:227, w1:3.740777561325208, w2:1.4158430710543157, bias:-2.388682104920817, loss:0.4926159035548014\n",
      "epoch:228, w1:3.751510425391147, w2:1.4162216625163582, bias:-2.393392046597421, loss:0.4923400334557782\n",
      "epoch:229, w1:3.7622225384038157, w2:1.4165973055376, bias:-2.398091136933194, loss:0.4920652659239369\n",
      "epoch:230, w1:3.772913937419856, w2:1.4169700671364103, bias:-2.4027794434676064, loss:0.4917915957559304\n",
      "epoch:231, w1:3.783584659679165, w2:1.417340013040245, bias:-2.407457032822888, loss:0.49151901778021734\n",
      "epoch:232, w1:3.7942347425994543, w2:1.4177072077093518, bias:-2.412123970719756, loss:0.4912475268566808\n",
      "epoch:233, w1:3.804864223770903, w2:1.4180717143600363, bias:-2.4167803219928548, loss:0.4909771178762567\n",
      "epoch:234, w1:3.8154731409509055, w2:1.418433594987496, bias:-2.4214261506059125, loss:0.4907077857605718\n",
      "epoch:235, w1:3.8260615320589157, w2:1.4187929103882317, bias:-2.426061519666623, loss:0.49043952546159064\n",
      "epoch:236, w1:3.83662943517138, w2:1.4191497201820455, bias:-2.4306864914412545, loss:0.4901723319612717\n",
      "epoch:237, w1:3.8471768885167634, w2:1.41950408283363, bias:-2.4353011273689953, loss:0.4899062002712329\n",
      "epoch:238, w1:3.857703930470663, w2:1.4198560556737607, bias:-2.4399054880760342, loss:0.48964112543242444\n",
      "epoch:239, w1:3.8682105995510105, w2:1.4202056949200956, bias:-2.444499633389389, loss:0.48937710251481087\n",
      "epoch:240, w1:3.8786969344133597, w2:1.4205530556975927, bias:-2.4490836223504795, loss:0.48911412661705983\n",
      "epoch:241, w1:3.8891629738462594, w2:1.4208981920585493, bias:-2.45365751322846, loss:0.48885219286623943\n",
      "epoch:242, w1:3.8996087567667086, w2:1.4212411570022738, bias:-2.4582213635333026, loss:0.48859129641752214\n",
      "epoch:243, w1:3.910034322215694, w2:1.4215820024943946, bias:-2.4627752300286496, loss:0.48833143245389626\n",
      "epoch:244, w1:3.920439709353808, w2:1.4219207794858135, bias:-2.4673191687444302, loss:0.48807259618588394\n",
      "epoch:245, w1:3.930824957456947, w2:1.4222575379313118, bias:-2.471853234989249, loss:0.48781478285126634\n",
      "epoch:246, w1:3.9411901059120837, w2:1.422592326807813, bias:-2.4763774833625503, loss:0.4875579877148143\n",
      "epoch:247, w1:3.9515351942131214, w2:1.422925194132311, bias:-2.4808919677665644, loss:0.4873022060680255\n",
      "epoch:248, w1:3.9618602619568177, w2:1.4232561869794709, bias:-2.485396741418036, loss:0.487047433228868\n",
      "epoch:249, w1:3.972165348838788, w2:1.4235853514989025, bias:-2.489891856859742, loss:0.4867936645415293\n",
      "epoch:250, w1:3.982450494649576, w2:1.4239127329321233, bias:-2.494377365971801, loss:0.48654089537617085\n",
      "epoch:251, w1:3.9927157392707997, w2:1.4242383756292052, bias:-2.49885331998278, loss:0.48628912112868766\n",
      "epoch:252, w1:4.002961122671366, w2:1.42456232306512, bias:-2.503319769480601, loss:0.48603833722047357\n",
      "epoch:253, w1:4.013186684903756, w2:1.4248846178557855, bias:-2.50777676442325, loss:0.48578853909819186\n",
      "epoch:254, w1:4.023392466100375, w2:1.4252053017738153, bias:-2.512224354149295, loss:0.4855397222335499\n",
      "epoch:255, w1:4.033578506469971, w2:1.425524415763985, bias:-2.516662587388215, loss:0.4852918821230787\n",
      "epoch:256, w1:4.043744846294124, w2:1.4258419999584127, bias:-2.5210915122705426, loss:0.4850450142879177\n",
      "epoch:257, w1:4.053891525923789, w2:1.4261580936914633, bias:-2.525511176337824, loss:0.48479911427360317\n",
      "epoch:258, w1:4.064018585775913, w2:1.4264727355143816, bias:-2.529921626552404, loss:0.48455417764986114\n",
      "epoch:259, w1:4.074126066330109, w2:1.4267859632096573, bias:-2.534322909307031, loss:0.48431020001040465\n",
      "epoch:260, w1:4.084214008125393, w2:1.4270978138051291, bias:-2.5387150704342933, loss:0.48406717697273477\n",
      "epoch:261, w1:4.094282451756979, w2:1.4274083235878308, bias:-2.5430981552158864, loss:0.4838251041779449\n",
      "epoch:262, w1:4.104331437873139, w2:1.4277175281175865, bias:-2.5474722083917123, loss:0.48358397729053065\n",
      "epoch:263, w1:4.114361007172114, w2:1.428025462240357, bias:-2.5518372741688182, loss:0.4833437919982009\n",
      "epoch:264, w1:4.124371200399091, w2:1.4283321601013441, bias:-2.5561933962301766, loss:0.4831045440116944\n",
      "epoch:265, w1:4.134362058343228, w2:1.4286376551578572, bias:-2.5605406177433045, loss:0.48286622906459864\n",
      "epoch:266, w1:4.144333621834739, w2:1.4289419801919439, bias:-2.564878981368735, loss:0.48262884291317154\n",
      "epoch:267, w1:4.1542859317420335, w2:1.429245167322793, bias:-2.569208529268332, loss:0.48239238133616846\n",
      "epoch:268, w1:4.164219028968911, w2:1.4295472480189122, bias:-2.573529303113461, loss:0.48215684013466936\n",
      "epoch:269, w1:4.174132954451802, w2:1.4298482531100827, bias:-2.577841344093013, loss:0.481922215131912\n",
      "epoch:270, w1:4.184027749157071, w2:1.430148212799099, bias:-2.5821446929212852, loss:0.4816885021731251\n",
      "epoch:271, w1:4.1939034540783595, w2:1.4304471566732948, bias:-2.5864393898457227, loss:0.4814556971253665\n",
      "epoch:272, w1:4.203760110233989, w2:1.4307451137158596, bias:-2.5907254746545223, loss:0.4812237958773629\n",
      "epoch:273, w1:4.213597758664405, w2:1.4310421123169506, bias:-2.5950029866841016, loss:0.480992794339352\n",
      "epoch:274, w1:4.223416440429678, w2:1.4313381802846028, bias:-2.5992719648264337, loss:0.48076268844292946\n",
      "epoch:275, w1:4.233216196607044, w2:1.4316333448554421, bias:-2.6035324475362565, loss:0.48053347414089403\n",
      "epoch:276, w1:4.242997068288498, w2:1.4319276327052033, bias:-2.607784472838149, loss:0.48030514740709995\n",
      "epoch:277, w1:4.252759096578431, w2:1.4322210699590585, bias:-2.612028078333486, loss:0.4800777042363081\n",
      "epoch:278, w1:4.262502322591309, w2:1.4325136822017583, bias:-2.616263301207267, loss:0.4798511406440404\n",
      "epoch:279, w1:4.272226787449408, w2:1.4328054944875899, bias:-2.620490178234828, loss:0.47962545266643786\n",
      "epoch:280, w1:4.281932532280578, w2:1.433096531350154, bias:-2.6247087457884315, loss:0.4794006363601184\n",
      "epoch:281, w1:4.291619598216061, w2:1.4333868168119661, bias:-2.628919039843741, loss:0.4791766878020384\n",
      "epoch:282, w1:4.301288026388348, w2:1.4336763743938834, bias:-2.633121095986182, loss:0.4789536030893553\n",
      "epoch:283, w1:4.3109378579290745, w2:1.4339652271243617, bias:-2.637314949417191, loss:0.478731378339293\n",
      "epoch:284, w1:4.320569133966964, w2:1.4342533975485452, bias:-2.6415006349603525, loss:0.47851000968900853\n",
      "epoch:285, w1:4.330181895625803, w2:1.4345409077371913, bias:-2.6456781870674306, loss:0.4782894932954603\n",
      "epoch:286, w1:4.339776184022467, w2:1.4348277792954356, bias:-2.6498476398242916, loss:0.47806982533527886\n",
      "epoch:287, w1:4.349352040264972, w2:1.435114033371397, bias:-2.6540090269567256, loss:0.47785100200463954\n",
      "epoch:288, w1:4.358909505450577, w2:1.4353996906646287, bias:-2.658162381836163, loss:0.4776330195191349\n",
      "epoch:289, w1:4.368448620663914, w2:1.4356847714344168, bias:-2.6623077374852917, loss:0.47741587411365194\n",
      "epoch:290, w1:4.377969426975163, w2:1.4359692955079275, bias:-2.666445126583577, loss:0.4771995620422475\n",
      "epoch:291, w1:4.387471965438257, w2:1.43625328228821, bias:-2.6705745814726813, loss:0.47698407957802763\n",
      "epoch:292, w1:4.396956277089129, w2:1.436536750762052, bias:-2.674696134161793, loss:0.476769423013028\n",
      "epoch:293, w1:4.406422402943988, w2:1.4368197195076962, bias:-2.6788098163328593, loss:0.47655558865809444\n",
      "epoch:294, w1:4.415870383997634, w2:1.4371022067024166, bias:-2.682915659345727, loss:0.4763425728427668\n",
      "epoch:295, w1:4.425300261221806, w2:1.437384230129958, bias:-2.6870136942431952, loss:0.476130371915163\n",
      "epoch:296, w1:4.434712075563564, w2:1.4376658071878416, bias:-2.69110395175598, loss:0.47591898224186396\n",
      "epoch:297, w1:4.4441058679436996, w2:1.4379469548945394, bias:-2.6951864623075887, loss:0.4757084002078021\n",
      "epoch:298, w1:4.453481679255187, w2:1.4382276898965187, bias:-2.6992612560191143, loss:0.47549862221614797\n",
      "epoch:299, w1:4.462839550361659, w2:1.4385080284751603, bias:-2.703328362713941, loss:0.4752896446882009\n",
      "epoch:300, w1:4.472179522095915, w2:1.438787986553552, bias:-2.707387811922373, loss:0.4750814640632793\n",
      "epoch:301, w1:4.4815016352584625, w2:1.439067579703159, bias:-2.711439632886177, loss:0.47487407679861204\n",
      "epoch:302, w1:4.49080593061609, w2:1.4393468231503754, bias:-2.7154838545630504, loss:0.47466747936923254\n",
      "epoch:303, w1:4.500092448900464, w2:1.4396257317829577, bias:-2.7195205056310083, loss:0.47446166826787173\n",
      "epoch:304, w1:4.5093612308067605, w2:1.4399043201563404, bias:-2.723549614492697, loss:0.4742566400048545\n",
      "epoch:305, w1:4.518612316992322, w2:1.440182602499841, bias:-2.72757120927963, loss:0.4740523911079949\n",
      "epoch:306, w1:4.527845748075346, w2:1.4404605927227512, bias:-2.731585317856352, loss:0.4738489181224942\n",
      "epoch:307, w1:4.537061564633595, w2:1.440738304420319, bias:-2.7355919678245306, loss:0.47364621761083875\n",
      "epoch:308, w1:4.546259807203141, w2:1.441015750879624, bias:-2.7395911865269764, loss:0.47344428615270023\n",
      "epoch:309, w1:4.555440516277136, w2:1.4412929450853456, bias:-2.7435830010515936, loss:0.4732431203448344\n",
      "epoch:310, w1:4.564603732304602, w2:1.4415698997254285, bias:-2.747567438235262, loss:0.473042716800984\n",
      "epoch:311, w1:4.573749495689255, w2:1.441846627196646, bias:-2.7515445246676515, loss:0.4728430721517801\n",
      "epoch:312, w1:4.58287784678835, w2:1.4421231396100629, bias:-2.7555142866949733, loss:0.4726441830446452\n",
      "epoch:313, w1:4.591988825911552, w2:1.4423994487964005, bias:-2.759476750423661, loss:0.4724460461436974\n",
      "epoch:314, w1:4.601082473319831, w2:1.4426755663113053, bias:-2.763431941723993, loss:0.47224865812965516\n",
      "epoch:315, w1:4.610158829224385, w2:1.4429515034405223, bias:-2.7673798862336514, loss:0.47205201569974303\n",
      "epoch:316, w1:4.619217933785582, w2:1.4432272712049754, bias:-2.7713206093612155, loss:0.47185611556759816\n",
      "epoch:317, w1:4.628259827111926, w2:1.4435028803657577, bias:-2.7752541362896017, loss:0.4716609544631776\n",
      "epoch:318, w1:4.63728454925905, w2:1.44377834142903, bias:-2.7791804919794383, loss:0.47146652913266657\n",
      "epoch:319, w1:4.646292140228726, w2:1.4440536646508326, bias:-2.7830997011723855, loss:0.4712728363383867\n",
      "epoch:320, w1:4.655282639967903, w2:1.4443288600418103, bias:-2.787011788394397, loss:0.4710798728587066\n",
      "epoch:321, w1:4.664256088367763, w2:1.4446039373718518, bias:-2.7909167779589263, loss:0.4708876354879519\n",
      "epoch:322, w1:4.673212525262796, w2:1.4448789061746472, bias:-2.7948146939700766, loss:0.470696121036316\n",
      "epoch:323, w1:4.682151990429907, w2:1.445153775752162, bias:-2.7987055603256983, loss:0.4705053263297723\n",
      "epoch:324, w1:4.691074523587528, w2:1.445428555179031, bias:-2.8025894007204317, loss:0.4703152482099871\n",
      "epoch:325, w1:4.6999801643947645, w2:1.4457032533068734, bias:-2.8064662386487, loss:0.47012588353423135\n",
      "epoch:326, w1:4.708868952450553, w2:1.445977878768531, bias:-2.8103360974076472, loss:0.4699372291752969\n",
      "epoch:327, w1:4.7177409272928434, w2:1.4462524399822285, bias:-2.81419900010003, loss:0.46974928202140903\n",
      "epoch:328, w1:4.726596128397797, w2:1.4465269451556608, bias:-2.818054969637057, loss:0.4695620389761421\n",
      "epoch:329, w1:4.735434595179007, w2:1.446801402290005, bias:-2.82190402874118, loss:0.4693754969583367\n",
      "epoch:330, w1:4.744256366986734, w2:1.4470758191838622, bias:-2.82574619994884, loss:0.46918965290201436\n",
      "epoch:331, w1:4.753061483107164, w2:1.4473502034371264, bias:-2.8295815056131626, loss:0.469004503756296\n",
      "epoch:332, w1:4.76184998276168, w2:1.4476245624547852, bias:-2.833409967906611, loss:0.46882004648531833\n",
      "epoch:333, w1:4.770621905106156, w2:1.4478989034506518, bias:-2.8372316088235907, loss:0.46863627806815394\n",
      "epoch:334, w1:4.779377289230264, w2:1.448173233451029, bias:-2.841046450183012, loss:0.4684531954987285\n",
      "epoch:335, w1:4.7881161741568015, w2:1.4484475592983093, bias:-2.8448545136308083, loss:0.46827079578574116\n",
      "epoch:336, w1:4.796838598841035, w2:1.448721887654507, bias:-2.848655820642411, loss:0.46808907595258414\n",
      "epoch:337, w1:4.805544602170057, w2:1.4489962250047304, bias:-2.852450392525183, loss:0.467908033037264\n",
      "epoch:338, w1:4.814234222962166, w2:1.4492705776605888, bias:-2.8562382504208115, loss:0.4677276640923221\n",
      "epoch:339, w1:4.822907499966253, w2:1.4495449517635393, bias:-2.860019415307658, loss:0.4675479661847561\n",
      "epoch:340, w1:4.831564471861215, w2:1.4498193532881727, bias:-2.8637939080030708, loss:0.46736893639594346\n",
      "epoch:341, w1:4.840205177255373, w2:1.4500937880454414, bias:-2.8675617491656573, loss:0.4671905718215625\n",
      "epoch:342, w1:4.848829654685914, w2:1.4503682616858278, bias:-2.8713229592975185, loss:0.46701286957151705\n",
      "epoch:343, w1:4.85743794261834, w2:1.4506427797024561, bias:-2.875077558746444, loss:0.46683582676985935\n",
      "epoch:344, w1:4.866030079445939, w2:1.450917347434149, bias:-2.8788255677080725, loss:0.4666594405547149\n",
      "epoch:345, w1:4.874606103489267, w2:1.4511919700684275, bias:-2.882567006228014, loss:0.46648370807820677\n",
      "epoch:346, w1:4.883166052995643, w2:1.4514666526444582, bias:-2.8863018942039362, loss:0.4663086265063812\n",
      "epoch:347, w1:4.891709966138657, w2:1.4517414000559465, bias:-2.8900302513876173, loss:0.466134193019133\n",
      "epoch:348, w1:4.900237881017698, w2:1.4520162170539788, bias:-2.893752097386962, loss:0.4659604048101324\n",
      "epoch:349, w1:4.9087498356574875, w2:1.4522911082498116, bias:-2.8974674516679864, loss:0.4657872590867513\n",
      "epoch:350, w1:4.917245868007634, w2:1.4525660781176122, bias:-2.901176333556766, loss:0.46561475306999006\n",
      "epoch:351, w1:4.925726015942192, w2:1.4528411309971487, bias:-2.9048787622413546, loss:0.4654428839944057\n",
      "epoch:352, w1:4.9341903172592385, w2:1.453116271096432, bias:-2.9085747567736684, loss:0.4652716491080398\n",
      "epoch:353, w1:4.942638809680464, w2:1.45339150249431, bias:-2.91226433607134, loss:0.46510104567234706\n",
      "epoch:354, w1:4.95107153085077, w2:1.453666829143015, bias:-2.9159475189195407, loss:0.4649310709621242\n",
      "epoch:355, w1:4.959488518337886, w2:1.453942254870665, bias:-2.919624323972772, loss:0.46476172226543927\n",
      "epoch:356, w1:4.967889809631988, w2:1.4542177833837202, bias:-2.9232947697566276, loss:0.4645929968835612\n",
      "epoch:357, w1:4.976275442145338, w2:1.4544934182693938, bias:-2.9269588746695274, loss:0.46442489213089116\n",
      "epoch:358, w1:4.984645453211936, w2:1.4547691629980217, bias:-2.93061665698442, loss:0.464257405334892\n",
      "epoch:359, w1:4.9929998800871696, w2:1.4550450209253871, bias:-2.934268134850457, loss:0.46409053383601956\n",
      "epoch:360, w1:5.001338759947489, w2:1.4553209952950035, bias:-2.9379133262946424, loss:0.46392427498765465\n",
      "epoch:361, w1:5.00966212989009, w2:1.4555970892403576, bias:-2.9415522492234514, loss:0.46375862615603475\n",
      "epoch:362, w1:5.0179700269326, w2:1.45587330578711, bias:-2.9451849214244237, loss:0.46359358472018636\n",
      "epoch:363, w1:5.026262488012782, w2:1.456149647855258, bias:-2.94881136056773, loss:0.4634291480718573\n",
      "epoch:364, w1:5.0345395499882475, w2:1.456426118261257, bias:-2.952431584207713, loss:0.46326531361545026\n",
      "epoch:365, w1:5.042801249636176, w2:1.4567027197201048, bias:-2.956045609784402, loss:0.46310207876795667\n",
      "epoch:366, w1:5.051047623653049, w2:1.4569794548473887, bias:-2.9596534546250037, loss:0.46293944095888917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5.051047623653049, 1.4569794548473887, -2.9596534546250037)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(X_train_scaled['age'], X_train_scaled['affordibility'], y_train, 1000, 0.4631)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ML-projects')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a6bbf90d6f54b643658b03f8dd324b7c374f3b85b6ca7d6caf20627e9bc767ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
